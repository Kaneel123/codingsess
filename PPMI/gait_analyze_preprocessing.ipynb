{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI Gait Analysis\n",
    "This data set is part of the Parkinson's Progression Markers Initiative. Anat Mirelman, PhD, of Tel Aviv University is the PI. According to the study summary: \"The Gait study was proposed in order to obtain quantitative, objective motor measures that could\n",
    "inform on pre-clinical symptoms, progression markers, and dynamic changes of function throughout disease and potential modifiers and mediators of motor symptoms.\"\n",
    "\n",
    "My goals are to explore the data set to see if I can come up with an interesting clinical question, and to also improve my data science skills. One interesting question is to try and classify each subject according to these gait measures. The main categories of subjects are individuals who have a genetic marker for PD (e.g., LRRK2) but do not show signs of PD, and those who have a genetic marker and do have diagnoses of PD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import linalg as LA\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# This sets a higher resolution for figures\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the necessary data sets. The Gait_Data data are the objective gait measures. The Screening data contain information on all > 600 individuals participating in PPMI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "gait = pd.read_csv('Gait_Data___Arm_swing.csv')\n",
    "screen_all = pd.read_csv('Screening___Demographics.csv')\n",
    "updrs = pd.read_csv('MDS_UPDRS_Part_III.csv')\n",
    "gait.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From screening data, I only care about a few variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'PATNO', 'APPRDX', 'CURRENT_APPRDX', 'BIRTHDT', 'GENDER'\n",
    "key_vars = ['PATNO', 'APPRDX', 'CURRENT_APPRDX', 'BIRTHDT', 'GENDER']\n",
    "screen_filt = screen_all[key_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For UPDRS Part III (motor scores), I only care about the 33 variables related to the testing instrument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updrs_vars = ['PATNO', 'INFODT', 'NP3SPCH', 'NP3FACXP', 'NP3RIGN', 'NP3RIGRU', 'NP3RIGLU', 'PN3RIGRL', 'NP3RIGLL', \n",
    "              'NP3FTAPR', 'NP3FTAPL', 'NP3HMOVR', 'NP3HMOVL', 'NP3PRSPR', 'NP3PRSPL', 'NP3TTAPR', \n",
    "              'NP3TTAPL', 'NP3LGAGR', 'NP3LGAGL', 'NP3RISNG', 'NP3GAIT', 'NP3FRZGT', 'NP3PSTBL', \n",
    "              'NP3POSTR', 'NP3BRADY', 'NP3PTRMR', 'NP3PTRML', 'NP3KTRMR', 'NP3KTRML', 'NP3RTARU', \n",
    "              'NP3RTALU', 'NP3RTARL', 'NP3RTALL', 'NP3RTALJ', 'NP3RTCON']\n",
    "updrs_filt = updrs[updrs_vars]\n",
    "updrs_filt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now I want to create new dataframe that only includes patients common to both gait and screen_filt\n",
    "df_merged = pd.merge(gait, screen_filt, how='inner', on=['PATNO'])\n",
    "\n",
    "# Did all of the subjects keep same diagnosis? If so, you can drop one of the dx columns \n",
    "print(\"Subjects kept same dx? \" + str(sum(df_merged['APPRDX'] == df_merged['CURRENT_APPRDX']) == len(df_merged)))\n",
    "\n",
    "# Let's drop some more columns\n",
    "df_merged = df_merged.drop(columns=['CURRENT_APPRDX', 'EVENT_ID', 'COHORT'])\n",
    "\n",
    "df_merged.columns\n",
    "\n",
    "print(len(np.unique(df_merged['PATNO'])))\n",
    "print(len(df_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# keep track of the cols (excluding UDPRS scores) that we want to keep later when we drop rows based on NaNs\n",
    "predictor_cols = ['SP_U', 'RA_AMP_U', 'LA_AMP_U', 'RA_STD_U',\n",
    "       'LA_STD_U', 'SYM_U', 'R_JERK_U', 'L_JERK_U', 'ASA_U', 'ASYM_IND_U',\n",
    "       'TRA_U', 'T_AMP_U', 'CAD_U', 'STR_T_U', 'STR_CV_U', 'STEP_REG_U',\n",
    "       'STEP_SYM_U', 'JERK_T_U', 'SP__DT', 'RA_AMP_DT', 'LA_AMP_DT',\n",
    "       'RA_STD_DT', 'LA_STD_DT', 'SYM_DT', 'R_JERK_DT', 'L_JERK_DT', 'ASA_DT',\n",
    "       'ASYM_IND_DT', 'TRA_DT', 'T_AMP_DT', 'CAD_DT', 'STR_T_DT', 'STR_CV_DT',\n",
    "       'STEP_REG_DT', 'STEP_SYM_DT', 'JERK_T_DT', 'SW_VEL_OP', 'SW_PATH_OP',\n",
    "       'SW_FREQ_OP', 'SW_JERK_OP', 'SW_VEL_CL', 'SW_PATH_CL', 'SW_FREQ_CL',\n",
    "       'SW_JERK_CL', 'TUG1_DUR', 'TUG1_STEP_NUM', 'TUG1_STRAIGHT_DUR',\n",
    "       'TUG1_TURNS_DUR', 'TUG1_STEP_REG', 'TUG1_STEP_SYM', 'TUG2_DUR',\n",
    "       'TUG2_STEP_NUM', 'TUG2_STRAIGHT_DUR', 'TUG2_TURNS_DUR', 'TUG2_STEP_REG',\n",
    "       'TUG2_STEP_SYM']\n",
    "\n",
    "# How many unique subjects are there? \n",
    "print(len(np.unique(gait['PATNO'])))\n",
    "print(len(np.unique(df_merged['PATNO'])))\n",
    "print(len(df_merged))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create another data frame that contains data only from each patient's initial visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We first need to format the dates correctly. Note that this method imputes day of month, but it doesn't matter\n",
    "# since we only have month and year\n",
    "df_merged['INFODATE'] = [datetime.strptime(x, '%m/%Y') for x in df_merged['INFODT']]\n",
    "\n",
    "# Next we want to create new data frame with only first visit's data\n",
    "df_baseline = df_merged.sort_values('INFODATE').groupby(['PATNO'], as_index=False).first()\n",
    "df_baseline.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out how many subjects were assessed on multiple visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pts = df_merged.groupby('PATNO', as_index=False).count()\n",
    "df_pts['MULT_VISITS'] = [1 if x > 1 else 0 for x in df_pts['INFODT']]\n",
    "df_mult_visits = df_pts[df_pts['MULT_VISITS']==1]\n",
    "print(len(df_mult_visits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment next line if you want to print the current data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_baseline.to_csv('gait_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start to look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_baseline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix \n",
    "sns.heatmap(df_baseline.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each variable against every other -- runtime is very slow, so don't include too much\n",
    "sns.pairplot(df_baseline[['SP_U', 'RA_AMP_U', \n",
    "       'RA_STD_U', 'SYM_U', 'R_JERK_U', 'SP__DT', 'RA_AMP_DT',\n",
    "       'RA_STD_DT', 'SYM_DT', 'R_JERK_DT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of patients with each diagnosis\n",
    "print(df_baseline.groupby('APPRDX').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_baseline.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count how many subjects have missing data\n",
    "print(df_baseline.isna().any(axis=1).sum())\n",
    "\n",
    "df_baseline.info()\n",
    "\n",
    "# Create new data frame that excludes subjects with missing data\n",
    "df_filt = df_baseline.dropna(subset=predictor_cols)\n",
    "\n",
    "print(len(df_filt))\n",
    "\n",
    "# Now how many subjects are there per group?\n",
    "print(df_filt.groupby('APPRDX', as_index=False).count())\n",
    "\n",
    "df_filt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the presentation on accessing PPMI data (\"08b_v2_Caspell_Foster_PPMI-Data-Access_May-2015-v2.0.pdf\"), the APPRDX codes in our data set correspond to:\n",
    "\n",
    "**4 - Prodromal** (this means an individual who appears at risk for PD based on report of \"anosmia\" or disrupted REM behavior)\n",
    "\n",
    "**5 - Genetic Cohort subject with PD**\n",
    "\n",
    "**6 - Genetic Cohort subject unaffected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above classifications, we want to classify subjects as either having PD (APPRDX=5) or no PD (APPRDX=4 or 6)\n",
    "ParkDx = [1 if x == 5 else 0 for x in df_filt['APPRDX']]\n",
    "\n",
    "# add Parkinson's disease binary variable to data frame\n",
    "df_filt = df_filt.assign(PD=ParkDx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filt.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
